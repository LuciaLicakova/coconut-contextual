# TASK: Reproduce the Coconut training curriculum (CoT stage, then latent stage) on the original data with the original model, running on either CPU, a single GPU, or multiple GPUs.

# PREPARATION
# Fork https://github.com/facebookresearch/coconut on GitHub (make a personal copy (a fork) under your GitHub account)
# Create a local folder called coconut-cpu-mini containing the forkâ€™s code.
git clone https://github.com/LuciaLicakova/coconut-cpu-mini.git coconut-cpu-mini
cd coconut-cpu-mini
# Do not edit directly on main, go to a branch called cpu-mini.
git checkout -b cpu-mini
# Make and activate a virtual environment
python -m venv .venv
.venv\Scripts\activate.bat
# Install required packages
pip install --upgrade pip
pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
pip install transformers>=4.42 datasets pyyaml tqdm
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# REPRODUCING EXPERIMENTS
# Preprocess files to have gsm_train.json, gsm_test.json, gsm_valid.json in coconut-cpu-mini/data
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini> python preprocessing/prepare_gsm.py 
# Create CPU-friendly configuration files that tell Coconut how to train the model on the GSM8K dataset: cpu_args\gsm_cot_cpu.yaml (stage 0), cpu_args\gsm_coconut_cpu.yaml (stage 1), cpu_args\gsm_coconut_eval_cpu.yaml

# MULTIPLE GPUS
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini>wandb login
# Before re-running the Coconut training, move the unstable checkpoints: mv exps/gsm8k_coconut_cpu/gsm-coconut/checkpoint_* \
   /system/user/studentwork/licakova/backup_coconut_checkpoints/

# Train on CPU with CoT as stage 0
python run.py cpu_args/gsm_cot_cpu.yaml

# IML Student Servers: to save logs in your work directory /system/user/studentwork/licakova/ (200GB quota)
mkdir -p /system/user/studentwork/licakova/logs

# Train on GPU
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini>
ssh -p 5792 licakova@student01.ai-lab.jku.at
D3a3SeNH
# Update the Google Sheet: enter licakova and the GPU number to reserve it
# Activate environment
source /system/apps/studentenv/miniconda3/bashrc
conda activate coconut
cd /system/user/studentwork/licakova/coconut-cpu-mini
# Start training using tmux (keeps running if you log out)
tmux new -s coconut
# Run on a single GPU
CUDA_VISIBLE_DEVICES=1 python run.py cpu_args/gsm_cot_cpu.yaml
CUDA_VISIBLE_DEVICES=0 torchrun --nnodes=1 --nproc_per_node=1 run.py cpu_args/gsm_cot_cpu.yaml
# 2 GPUs --not working CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py args/gsm_cot.yaml
# to see the output, trying with batch_size_traning: 16 and then 8
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_cot_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_2gpu_resume.log
# TRAIN THE FIRST LATENT STAGE
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_coconut_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_coconut_latent.log
---
# Save the output into approach.txt: grep -n "Accuracy on validation set" /system/user/studentwork/licakova/logs/output_coconut_latent.log
# EVALUATE THE FIRST LATENT STAGE AND ALSO EVALUATE THE BEST COT CHECKPOINT FOR A BASELINE COMPARISON
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_coconut_eval_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_coconut_eval.log


# Read the traceback INSIDE [licakova@student01 coconut-cpu-mini]$
less /system/user/studentwork/licakova/logs/output_2gpu_resume.log
less /system/user/studentwork/licakova/logs/output_coconut_latent.log


# After modifying locally
ctrl+b d
# Leave the ssh session
exit
# Update from local Windows PowerShell
scp -P 5792 C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\run.py licakova@student01.ai-lab.jku.at:/system/user/studentwork/licakova/coconut-cpu-mini/
scp -P 5792 -r C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\cpu_args licakova@student01.ai-lab.jku.at:/system/user/studentwork/licakova/coconut-cpu-mini/

# Attach tmux
ssh -p 5792 licakova@student01.ai-lab.jku.at
tmux attach -t coconut
# Run the code


# Once it starts, detach tmux: Ctrl+b then d
# Check progress, GPU usage, CPU/RAM usage anytime
tmux attach -t coconut 
nvidia-smi                  
top                         
# Update the Google Sheet to free the GPU.
-----------------------
# Ensure run.py works for a CPU (cpu_args, batch_size_training: 16), a single GPU (cpu_args), multiple GPUs (args)
# Run on multiple GPUs with the original batch size (only the effective batch size was maintained) to try to increase the accuracy

# Run actual latent reasoning (stage 1)
-- Select a checkpoint as the initialization of Coconut (the validation accuracy is expected to be around 40%). Replace the load_model_path in the args/gsm_coconut.yaml with the selected checkpoint, and run
python run.py cpu_args/gsm_coconut_cpu.yaml (MULTIPLE GPUS, torchrun)
# Evaluate: find the checkpoint with best validation accuracy (checkpoint 6), and put the path as load_model_path in args/gsm_coconut_eval.yaml. Then evaluate
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_coconut_eval_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_coconut_eval.log

# Conclude something
# Create datasets and yaml files for ProntoQA
# Repeat the steps (do the experiments) for ProntoQA
# Create datasets and yaml files for ProsQA
# Repeat the steps (do the experiments) for ProsQA

-----------------------------
checkpoint are stored under <configs.save_path>/<configs.name>/checkpoint_<N>
-----------------------------
OUTPUT CUDA_VISIBLE_DEVICES=1 python run.py cpu_args/gsm_cot_cpu.yaml (requires smaller batch size)
[licakova@student01 coconut-cpu-mini]$ tmux capture-pane -S - -E - -p > full_run.log
[licakova@student01 coconut-cpu-mini]$ grep -E "Accuracy on validation set|saving model" full_run.log
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 4 / 32 = 0.125
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 3 / 32 = 0.09375
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 1 / 32 = 0.03125

GSM-COT: after the full validation set has been evaluated per checkpoint 
EPOCHS 01-06
Accuracy on validation set: 127 / 500 = 0.254
Accuracy on validation set: 166 / 500 = 0.332
Accuracy on validation set: 187 / 500 = 0.374
Accuracy on validation set: 200 / 500 = 0.4
Accuracy on validation set: 205 / 500 = 0.41
Accuracy on validation set: 221 / 500 = 0.442
EPOCH 07
Accuracy on validation set: 206 / 500 = 0.412
EPOCH 08
Accuracy on validation set: 213 / 500 = 0.426
EPOCH 09
Accuracy on validation set: 210 / 500 = 0.42
EPOCH 10
Accuracy on validation set: 219 / 500 = 0.438
EPOCH 11
Accuracy on validation set: 225 / 500 = 0.45
EPOCH 12
Accuracy on validation set: 209 / 500 = 0.418
EPOCH 13
Accuracy on validation set: 219 / 500 = 0.438
EPOCH 14
Accuracy on validation set: 215 / 500 = 0.43
EPOCHS 15-25
Accuracy on validation set: 214 / 500 = 0.428
Accuracy on validation set: 217 / 500 = 0.434
Accuracy on validation set: 223 / 500 = 0.446
Accuracy on validation set: 220 / 500 = 0.44
Accuracy on validation set: 220 / 500 = 0.44
Accuracy on validation set: 223 / 500 = 0.446
Accuracy on validation set: 203 / 500 = 0.406
Accuracy on validation set: 225 / 500 = 0.45
Accuracy on validation set: 212 / 500 = 0.424
Accuracy on validation set: 218 / 500 = 0.436
Accuracy on validation set: 218 / 500 = 0.436

GSM-COCONUT-STAGE-1: CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_coconut_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_coconut_latent.log

grep -n "Accuracy on validation set" /system/user/studentwork/licakova/logs/output_coconut_latent.log
EPOCHS 5-25 (started from checkpoint 4)
113:Accuracy on validation set: 161 / 500 = 0.322
167:Accuracy on validation set: 183 / 500 = 0.366
216:Accuracy on validation set: 156 / 500 = 0.312
265:Accuracy on validation set: 162 / 500 = 0.324
314:Accuracy on validation set: 171 / 500 = 0.342
362:Accuracy on validation set: 152 / 500 = 0.304
410:Accuracy on validation set: 150 / 500 = 0.3
459:Accuracy on validation set: 160 / 500 = 0.32
503:Accuracy on validation set: 156 / 500 = 0.312
547:Accuracy on validation set: 154 / 500 = 0.308
591:Accuracy on validation set: 131 / 500 = 0.262
635:Accuracy on validation set: 167 / 500 = 0.334
679:Accuracy on validation set: 140 / 500 = 0.28
723:Accuracy on validation set: 126 / 500 = 0.252
767:Accuracy on validation set: 141 / 500 = 0.282
811:Accuracy on validation set: 144 / 500 = 0.288
855:Accuracy on validation set: 150 / 500 = 0.3
899:Accuracy on validation set: 142 / 500 = 0.284
943:Accuracy on validation set: 137 / 500 = 0.274
987:Accuracy on validation set: 133 / 500 = 0.266
1031:Accuracy on validation set: 84 / 500 = 0.168

GSM-COCONUT-EVAL (checkpoint 22 from stage 0 as a baseline CoT comparison: load_model_path: exps/gsm8k_cot_cpu/gsm-cot/checkpoint_22)
[licakova@student01 coconut-cpu-mini]$ grep "Accuracy on validation set" /system/user/studentwork/licakova/logs/output_coconut_eval.log
Accuracy on validation set: 567 / 1320 = 0.42954545454545456
CoT match on validation set: 245 / 1320 = 0.1856060606060606

GSM-COCONUT-EVAL (checkpoint 6 from stage 1 to report final Coconut results: load_model_path: exps/gsm8k_coconut_cpu/gsm-coconut/checkpoint_6)
[licakova@student01 coconut-cpu-mini]$ grep "Accuracy on validation set" /system/user/studentwork/licakova/logs/output_coconut_eval.log
Accuracy on validation set: 0 / 500 = 0.0

LOWER LR, GSM-COCONUT-STAGE-1:
EPOCHS 5-10 (started from checkpoint 4)
112:Accuracy on validation set: 161 / 500 = 0.322
166:Accuracy on validation set: 179 / 500 = 0.358
215:Accuracy on validation set: 134 / 500 = 0.268
264:Accuracy on validation set: 167 / 500 = 0.334
313:Accuracy on validation set: 166 / 500 = 0.332
360:Accuracy on validation set: 166 / 500 = 0.332


----------------------
# Preparing PrOntoQA
cd C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\preprocessing
git clone https://github.com/asaparov/prontoqa.git
cd prontoqa
python run_experiment.py --model-name json --model-size dummy --ordering random --num-trials 10000 --few-shot-examples 0 --ontology fictional --min-hops 5 --max-hops 5 --hops-skip 1
where
--model-name [gpt3|opt|unifiedqa|dummy] specifies the model to test. 
--model-size <size> for GPT-3, this must be the OpenAI identifier for the model. For example, to use the InstructGPT 350M parameter model, specify --model-size text-ada-001.
--ordering [postorder|preorder|random] the order of the context sentences of each question.
--num-trials <n> the number of examples per experiment.
--few-shot-examples <n> the number of in-context examples given in each experiment example.
--ontology [fictional|true|false] which ontology type to generate.
--min-hops <n>, --max-hops <m>, --hops-skip <k> specifies which hop counts to test. An experiment is run with n hops, then another experiment is run with n + k hops, n + 2k, and so on until the number of hops exceeds m.
--resume which experiment to continue from
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\preprocessing\prontoqa> python run_experiment.py --model-name json --model-size dummy --ordering random --num-trials 10000 --few-shot-examples 0 --ontology fictional --min-hops 5 --max-hops 5 --hops-skip 1

# TRAIN THE FIRST LATENT STAGE
ssh -p 5792 licakova@student01.ai-lab.jku.at
source /system/apps/studentenv/miniconda3/bashrc
conda activate coconut
cd /system/user/studentwork/licakova/coconut-cpu-mini
tmux new -s coconut_pr
tmux attach -t coconut_pr
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/prontoqa_coconut.yaml |& tee /system/user/studentwork/licakova/logs/prontoqa_coconut_latent.log


PRONTOQA TRAINING batch_size_training=8, gradient_accumulation_steps=2: grep -n "Accuracy on validation set" /system/user/studentwork/licakova/logs/prontoqa_coconut_latent.log 
EPOCHS 1-25
141:Accuracy on validation set: 110 / 200 = 0.55
231:Accuracy on validation set: 190 / 200 = 0.95
321:Accuracy on validation set: 190 / 200 = 0.95
411:Accuracy on validation set: 193 / 200 = 0.965
501:Accuracy on validation set: 194 / 200 = 0.97
586:Accuracy on validation set: 197 / 200 = 0.985
671:Accuracy on validation set: 200 / 200 = 1.0
756:Accuracy on validation set: 195 / 200 = 0.975
841:Accuracy on validation set: 199 / 200 = 0.995
926:Accuracy on validation set: 199 / 200 = 0.995
1006:Accuracy on validation set: 154 / 200 = 0.77
1085:Accuracy on validation set: 170 / 200 = 0.85
1165:Accuracy on validation set: 195 / 200 = 0.975
1245:Accuracy on validation set: 200 / 200 = 1.0
1325:Accuracy on validation set: 198 / 200 = 0.99
1400:Accuracy on validation set: 150 / 200 = 0.75
1475:Accuracy on validation set: 178 / 200 = 0.89
1550:Accuracy on validation set: 192 / 200 = 0.96
1625:Accuracy on validation set: 198 / 200 = 0.99
1700:Accuracy on validation set: 200 / 200 = 1.0
1770:Accuracy on validation set: 198 / 200 = 0.99
1840:Accuracy on validation set: 199 / 200 = 0.995
1910:Accuracy on validation set: 199 / 200 = 0.995
1980:Accuracy on validation set: 200 / 200 = 1.0
2050:Accuracy on validation set: 198 / 200 = 0.99
EPOCHS 26-50
2115:Accuracy on validation set: 193 / 200 = 0.965
2180:Accuracy on validation set: 199 / 200 = 0.995
2245:Accuracy on validation set: 200 / 200 = 1.0
2310:Accuracy on validation set: 199 / 200 = 0.995
2375:Accuracy on validation set: 193 / 200 = 0.965
2435:Accuracy on validation set: 194 / 200 = 0.97
2495:Accuracy on validation set: 198 / 200 = 0.99
2555:Accuracy on validation set: 198 / 200 = 0.99
2615:Accuracy on validation set: 200 / 200 = 1.0
2675:Accuracy on validation set: 200 / 200 = 1.0
2735:Accuracy on validation set: 199 / 200 = 0.995
2795:Accuracy on validation set: 200 / 200 = 1.0
2855:Accuracy on validation set: 200 / 200 = 1.0
2915:Accuracy on validation set: 199 / 200 = 0.995
2975:Accuracy on validation set: 200 / 200 = 1.0
3035:Accuracy on validation set: 200 / 200 = 1.0
3095:Accuracy on validation set: 200 / 200 = 1.0
3155:Accuracy on validation set: 198 / 200 = 0.99
3215:Accuracy on validation set: 199 / 200 = 0.995
3275:Accuracy on validation set: 200 / 200 = 1.0
3335:Accuracy on validation set: 200 / 200 = 1.0
3395:Accuracy on validation set: 200 / 200 = 1.0
3455:Accuracy on validation set: 200 / 200 = 1.0
3515:Accuracy on validation set: 198 / 200 = 0.99
3575:Accuracy on validation set: 199 / 200 = 0.995

PRONTOQA-COCONUT-EVAL (load_model_path: exps/prontoqa_coconut_cpu/prontoqa-coconut/checkpoint_48)
Loads the model from the checkpoint you give in load_model_path.
Prepares the test dataset.
Runs generation with the model on each validation question.
Computes metrics (validation accuracy and CoT match) and prints/logs them.
Exits immediately after evaluation (no optimizer, no checkpoint saving, no training loop).
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/prontoqa_coconut_eval.yaml |& tee /system/user/studentwork/licakova/logs/prontoqa_coconut_eval.log

[licakova@student01 coconut-cpu-mini]$ grep "Accuracy on validation set" /system/user/studentwork/licakova/logs/prontoqa_coconut_eval.log
Accuracy on validation set: 0 / 800 = 0.0
CoT match on validation set: 0 / 800 = 0.0

PRONTOQA TRAINING batch_size_training=8, gradient_accumulation_steps=4: grep -n "Accuracy on validation set" /system/user/studentwork/licakova/logs/prontoqa_coconut_latent.log





