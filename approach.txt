# TASK: Reproduce the Coconut training curriculum (CoT stage, then latent stage) on the original data with the original model, running on either CPU, a single GPU, or multiple GPUs.

# PREPARATION
# Fork https://github.com/facebookresearch/coconut on GitHub (make a personal copy (a fork) under your GitHub account)
# Create a local folder called coconut-cpu-mini containing the forkâ€™s code.
git clone https://github.com/LuciaLicakova/coconut-cpu-mini.git coconut-cpu-mini
cd coconut-cpu-mini
# Do not edit directly on main, go to a branch called cpu-mini.
git checkout -b cpu-mini
# Make and activate a virtual environment
python -m venv .venv
.venv\Scripts\activate.bat
# Install required packages
pip install --upgrade pip
pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
pip install transformers>=4.42 datasets pyyaml tqdm
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# REPRODUCING EXPERIMENTS
# Preprocess files to have gsm_train.json, gsm_test.json, gsm_valid.json in coconut-cpu-mini/data
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini> python preprocessing/prepare_gsm.py 
# Create CPU-friendly configuration files that tell Coconut how to train the model on the GSM8K dataset: cpu_args\gsm_cot_cpu.yaml (stage 0), cpu_args\gsm_coconut_cpu.yaml (stage 1), cpu_args\gsm_coconut_eval_cpu.yaml

# MULTIPLE GPUS
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini>wandb login
wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
wandb: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models
wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:
wandb: No netrc file found, creating one.
wandb: Appending key for api.wandb.ai to your netrc file: C:\Users\lucia\_netrc
wandb: Currently logged in as: lucia-licakova (lucia-licakova-johannes-kepler-universit-t-linz) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin

# Train on CPU with CoT as stage 0
python run.py cpu_args/gsm_cot_cpu.yaml

# IML Student Servers
# To save logs in your work directory /system/user/studentwork/licakova/ (200GB quota)
mkdir -p /system/user/studentwork/licakova/logs



# Train on GPU
PS C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini> ssh student01
ssh -p 5792 licakova@student01.ai-lab.jku.at
D3a3SeNH
nvidia-smi
# Update the Google Sheet: enter licakova and the GPU number to reserve it
# Activate environment
source /system/apps/studentenv/miniconda3/bashrc
conda activate coconut
cd /system/user/studentwork/licakova/coconut-cpu-mini
# Start training using tmux (keeps running if you log out)
tmux new -s coconut
# Run on a single GPU
CUDA_VISIBLE_DEVICES=1 python run.py cpu_args/gsm_cot_cpu.yaml
CUDA_VISIBLE_DEVICES=0 torchrun --nnodes=1 --nproc_per_node=1 run.py cpu_args/gsm_cot_cpu.yaml
# 2 GPUs
--not working CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py args/gsm_cot.yaml
# to see the output, trying with batch_size_traning: 16
CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py cpu_args/gsm_cot_cpu.yaml |& tee /system/user/studentwork/licakova/logs/output_2gpu_resume.log

# Read the traceback INSIDE [licakova@student01 coconut-cpu-mini]$ less /system/user/studentwork/licakova/logs/output_2gpu_resume.log


# After modifying locally
ctrl+b d
# Leave the ssh session
exit
# Update from local Windows PowerShell
scp -P 5792 C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\run.py licakova@student01.ai-lab.jku.at:/system/user/studentwork/licakova/coconut-cpu-mini/
scp -P 5792 -r C:\Users\lucia\AppData\Local\Programs\Python\Python310\coconut-cpu-mini\cpu_args licakova@student01.ai-lab.jku.at:/system/user/studentwork/licakova/coconut-cpu-mini/

# Attach tmux
ssh -p 5792 licakova@student01.ai-lab.jku.at
tmux attach -t coconut
# Run the code


# Once it starts, detach tmux: Ctrl+b then d
# Check progress, GPU usage, CPU/RAM usage anytime
tmux attach -t coconut 
nvidia-smi                  
top                         
# Update the Google Sheet to free the GPU.
-----------------------
# Ensure run.py works for a CPU (cpu_args, batch_size_training: 16), a single GPU (cpu_args), multiple GPUs (args)
# Run on multiple GPUs with the original batch size to try to increase the accuracy

# Run actual latent reasoning (stage 1)
-- Select a checkpoint as the initialization of Coconut (the validation accuracy is expected to be around 40%). Replace the load_model_path in the args/gsm_coconut.yaml with the selected checkpoint, and run
python run.py cpu_args/gsm_coconut_cpu.yaml (MULTIPLE GPUS, torchrun)
# Evaluate: find the checkpoint with best validation accuracy, and put the path as load_model_path in args/gsm_coconut_eval.yaml. Then evaluate
python run.py cpu_args/gsm_coconut_eval_cpu.yaml (MULTIPLE GPUS, torchrun)

# Conclude something
# Create datasets and yaml files for ProntoQA
# Repeat the steps (do the experiments) for ProntoQA
# Create datasets and yaml files for ProsQA
# Repeat the steps (do the experiments) for ProsQA


-----------------------------
Author
lucia-licakova
State
Running

Start time
September 17th, 2025 2:53:50 PM
Runtime
15m 46s
Tracked hours
-
Run path
lucia-licakova-johannes-kepler-universit-t-linz/coconut/zz2kjg85
Hostname
student01
OS
Linux-5.14.0-570.37.1.el9_6.x86_64-x86_64-with-glibc2.34
Python version
3.10.18
Python executable
/system/apps/studentenv/licakova/coconut/bin/python3.10
Git repository
git clone https://github.com/LuciaLicakova/coconut-cpu-mini.git
Git state
git checkout -b "gsm-cot" 1c8960fdc0e0b3f68d0b537bdf2c1dcc022f6553
Command
/system/user/studentwork/licakova/coconut-cpu-mini/run.py cpu_args/gsm_cot_cpu.yaml
System Hardware
CPU count	6
Logical CPU count	12
GPU count	4
GPU type	NVIDIA GeForce GTX 1080 Ti
W&B CLI Version
0.18.7



-----------------------------
OUTPUT CUDA_VISIBLE_DEVICES=1 python run.py cpu_args/gsm_cot_cpu.yaml (requires smaller batch size)
[licakova@student01 coconut-cpu-mini]$ tmux capture-pane -S - -E - -p > full_run.log
[licakova@student01 coconut-cpu-mini]$ grep -E "Accuracy on validation set|saving model" full_run.log
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 4 / 32 = 0.125
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 0 / 32 = 0.0
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 3 / 32 = 0.09375
Accuracy on validation set: 1 / 32 = 0.03125
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 2 / 32 = 0.0625
Accuracy on validation set: 1 / 32 = 0.03125

OUTPUT CUDA_VISIBLE_DEVICES=0,1 torchrun --nnodes=1 --nproc_per_node=2 run.py args/gsm_cot.yaml



